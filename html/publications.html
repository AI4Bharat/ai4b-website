<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link href='https://fonts.googleapis.com/css?family=Crimson Text' rel='stylesheet'>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"
        integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <title>Research Publications</title>
    <link rel="stylesheet" href="../styles/ai4b-styles.css">
</head>

<body>
    <div id="head_content"></div>
    <div class="filter-section">
        <div class="filter-row">
            <span class="filter-label">Year:</span>
            <button class="filter-btn" data-filter="year" data-value="2021">2021</button>
            <button class="filter-btn" data-filter="year" data-value="2022">2022</button>
            <button class="filter-btn" data-filter="year" data-value="2023">2023</button>
            <button class="filter-btn" data-filter="year" data-value="2023">2024</button>
        </div>
        <div class="filter-row">
            <span class="filter-label">Conference:</span>
            <button class="filter-btn" data-filter="conference" data-value="ACL">ACL</button>
            <button class="filter-btn" data-filter="conference" data-value="EMNLP">EMNLP</button>
            <button class="filter-btn" data-filter="conference" data-value="TMLR">TMLR</button>
            <button class="filter-btn" data-filter="conference" data-value="NAACL">NAACL</button>
            <button class="filter-btn" data-filter="conference" data-value="InterSpeech">InterSpeech</button>
        </div>
        <div class="filter-row">
            <span class="filter-label">Area:</span>
            <button class="filter-btn" data-filter="area" data-value="ASR">ASR</button>
            <button class="filter-btn" data-filter="area" data-value="MT">MT</button>
            <button class="filter-btn" data-filter="area" data-value="TTS">TTS</button>
            <button class="filter-btn" data-filter="area" data-value="LLM">LLM</button>
        </div>
    </div>

    <div class="publications">
        <!-- Example of a publication card -->
        <div class="publication-card" data-year="2021" data-conference="ACL" data-area="MT">
            <div class="publication-header">
                <span class="badge">ACL</span>
                <h2>Finding Blindspots in LLM Evaluations with Interpretable Checklists</h2>
                <p>Authors: Sumanth Doddapneni, et al., 2021</p>
                <div class="links">
                    <a href="abstract" class="abstract-link">Abstract</a>
                    <a href="github"><i class="fa-brands fa-github"></i></a>
                    <a href="arxiv"><i class="fa-regular fa-file-pdf"></i></a>
                </div>
            </div>
            <div class="abstract-content">
                <p>Large Language Models (LLMs) are increasingly relied upon to evaluate text outputs of other LLMs,
                    thereby influencing leaderboards and development decisions. However, concerns persist over the
                    accuracy of these assessments and the potential for misleading conclusions. In this work, we
                    investigate the effectiveness of LLMs as evaluators for text generation tasks. We propose FBI, a
                    novel framework designed to examine the proficiency of Evaluator LLMs in assessing four critical
                    abilities in other LLMs: factual accuracy, instruction following, coherence in long-form writing,
                    and reasoning proficiency. By introducing targeted perturbations in answers generated by LLMs, that
                    clearly impact one of these key capabilities, we test whether an Evaluator LLM can detect these
                    quality drops. By creating a total of 2400 perturbed answers covering 22 perturbation categories, we
                    conduct a comprehensive study using different evaluation strategies on five prominent LLMs commonly
                    used as evaluators in the literature. Our findings reveal significant shortcomings in current
                    Evaluator LLMs, which failed to identify quality drops in over 50\% of cases on average.
                    Single-answer and pairwise evaluations demonstrated notable limitations, whereas reference-based
                    evaluations showed comparatively better performance. These results underscore the unreliable nature
                    of current Evaluator LLMs and advocate for cautious implementation in practical applications. Code
                    and data are available at this https URL.</p>
            </div>
        </div>
        <div class="publication-card" data-year="2022" data-conference="NAACL" data-area="MT">
            <div class="publication-header">
                <span class="badge">NAACL</span>
                <h2>Finding1 Blindspots in LLM Evaluations with Interpretable Checklists</h2>
                <p>Authors: Sumanth Doddapneni, et al. 2022</p>
                <div class="links">
                    <a href="abstract" class="abstract-link">Abstract</a>
                    <a href="github"><i class="fa-brands fa-github"></i></a>
                    <a href="arxiv"><i class="fa-regular fa-file-pdf"></i></a>
                </div>
            </div>
            <div class="abstract-content">
                <p>Large Language Models (LLMs) are increasingly NAACL 2022...</p>
            </div>
        </div>
        <div class="publication-card" data-year="2023" data-conference="EMNLP" data-area="ASR">
            <div class="publication-header">
                <span class="badge">EMNLP</span>
                <h2>Finding2 Blindspots in LLM Evaluations with Interpretable Checklists</h2>
                <p>Authors: Sumanth Doddapneni, et al. 2023</p>
                <div class="links">
                    <a href="abstract" class="abstract-link">Abstract</a>
                    <a href="github"><i class="fa-brands fa-github"></i></a>
                    <a href="arxiv"><i class="fa-regular fa-file-pdf"></i></a>
                </div>
            </div>
            <div class="abstract-content">
                <p>Large Language Models (LLMs) are increasingly EMNLP 2023...</p>
            </div>
        </div>
        <div class="publication-card" data-year="2021" data-conference="InterSpeech" data-area="TTS">
            <div class="publication-header">
                <span class="badge">InterSpeech</span>
                <h2>Finding3 Blindspots in LLM Evaluations with Interpretable Checklists</h2>
                <p>Authors: Sumanth Doddapneni, et al. 2021</p>
                <div class="links">
                    <a href="abstract" class="abstract-link">Abstract</a>
                    <a href="github"><i class="fa-brands fa-github"></i></a>
                    <a href="arxiv"><i class="fa-regular fa-file-pdf"></i></a>
                </div>
            </div>
            <div class="abstract-content">
                <p>Large Language Models (LLMs) are increasingly Interspeech 2021...</p>
            </div>
        </div>
        <div class="publication-card" data-year="2023" data-conference="ACL" data-area="TTS">
            <div class="publication-header">
                <span class="badge">ACL</span>
                <h2>Finding4 Blindspots in LLM Evaluations with Interpretable Checklists</h2>
                <p>Authors: Sumanth Doddapneni, et al. 2023</p>
                <div class="links">
                    <a href="abstract" class="abstract-link">Abstract</a>
                    <a href="github"><i class="fa-brands fa-github"></i></a>
                    <a href="arxiv"><i class="fa-regular fa-file-pdf"></i></a>
                </div>
            </div>
            <div class="abstract-content">
                <p>Large Language Models (LLMs) are increasingly ACL 2023...</p>
            </div>
        </div>
        <div id="foot_content"></div>

        <!-- Add more publication cards here with the respective data-year, data-conference, and data-area attributes -->
    </div>

    <script src="../js/filter-pubs.js"></script>

    <script type="text/javascript">
        $('#head_content').load('header.html')
        $('#foot_content').load('footer.html')
    </script>
</body>

</html>