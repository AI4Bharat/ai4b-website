<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"
        integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    
    <link rel="stylesheet" href="../styles/ai4b-base.css">
    <link rel="stylesheet" href="../styles/ai4b-timeline.css">
    <title>Automatic Speech Recognition</title>
</head>

<body>
    <div id="head_content"></div>
    <div class="main">
        <div class="asr-section">
            <div class="left-panel">
                <h1>Automatic Speech Recognition</h1>
            </div>
            <div class="right-panel">
                <p>
                    At AI4Bharat, our commitment to Automatic Speech Recognition (ASR) is driven by a vision of
                    embracing and reflecting India's rich linguistic and cultural diversity. We are dedicated to creating inclusive
                    ASR systems that span all 22 constitutionally recognized languages. Our approach combines cutting-edge
                    engineering techniques for large-scale data crawling with meticulous ground-level data collection
                    across over 400 districts, resulting in a dataset of unprecedented magnitude. This includes 300,000 hours
                    of raw speech, 6,000 hours of transcribed data, and 6,400 hours of mined audio-text pairs, augmented by
                    pseudo-labeled data from diverse sources like YouTube. This extensive dataset empowers us to address
                    the complexities of India's linguistic landscape effectively. Our focus on building robust benchmarks is
                    exemplified by our work with Vistaar, IndicSUPERB, Lahaja, and Svarah, which have set new standards
                    in ASR evaluation. Our state-of-the-art models include IndicWav2Vec, IndicWhisper, and IndicConformer,
                    with our latest model supporting all 22 languages and demonstrating our commitment to technological
                    excellence. Moving forward, we aim to enhance our models to handle 8KZ telephony data, adapt them
                    for specific domains and demographics through synthetic data generation, and ensure their functionality
                    in offline settings, further advancing the frontiers of ASR technology for low-resource languages. </p>
                <button class="cta-button">Try out our latest model</button>
                <div class="highlight">To know more about our contributions over the years see the timeline below!</div>
            </div>
        </div>
        <div class="container">
            <ul>
                <li>
                    <h3 class="heading">IndicVoices 2.0</h3>
                    <p>IndicVoices 2.0 is a dataset of natural and spontaneous speech containing a total of 12000 hours of read (8%), extempore (76%) and conversational (15%) audio from 22563 speakers covering 208 Indian districts and 22 languages. Of these 12000 hours, 3200 hours have already been transcribed, with a median of 122 hours per language.</p>
                        <a href="https://github.com/AI4Bharat/IndicVoices"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2403.01926"><img src="../assets/logos/paper.png"></a>
                        <!-- <a href="jupyter"><img src="../assets/logos/colab.png"></i></a> -->
                    <span class="date dataset">June 2024</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">Lahaja</h3>
                    <p>Lahaja is a benchmark featuring 12.5 hours of Hindi audio to facilitate a comprehensive assessment of Hindi ASR systems across various accents. This dataset includes read and spontaneous speech on diverse topics, collected from 132 speakers across 83 districts in India.</p>
                        <a href="https://github.com/AI4Bharat/Lahaja"><img src="../assets/logos/github.png"></a>
                        <a href="arxiv"><img src="../assets/logos/paper.png"></a>
                    <span class="date dataset">June 2024</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">IndicVoices 1.0</h3>
                    <p>IndicVoices 1.0 is a dataset of natural and spontaneous speech containing a total of 7348 hours of read (9%), extempore (74%) and conversational (17%) audio from 16237 speakers covering 145 Indian districts and 22 languages. Of these 7348 hours, 1639 hours have already been transcribed, with a median of 73 hours per language.</p>
                        <a href="https://github.com/AI4Bharat/IndicVoices"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2403.01926"><img src="../assets/logos/paper.png"></a>
                    <span class="date dataset">March 2024</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">Svarah</h3>
                    <p>Svarah is a benchmark addressing gaps in ASR performance on Indian accents, featuring 9.6 hours of transcribed English audio from 117 speakers across 65 locations in India. It includes both read and spontaneous speech across various domains, ensuring diverse vocabulary.</p>
                        <a href="https://github.com/AI4Bharat/Svarah"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2305.15760"><img src="../assets/logos/paper.png"></a>
                    <span class="date dataset">August 2023</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">IndicWhisper</h3>
                    <p>IndicWhisper is finetuned on OpenAIâ€™s Whisper model using the Vistaar-train set with over 10,000 hours across 12 Indian languages</p>
                        <a href="https://github.com/AI4Bharat/vistaar"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2305.15386"><img src="../assets/logos/paper.png"></a>
                    <span class="date model">July 2023</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">Kathbath</h3>
                    <p>Kathbath is a comprehensive dataset comprising 1,684 hours of labeled speech data collected from 1,218 contributors across 203 districts in India, spanning 12 Indian languages. </p>
                        <a href="https://github.com/AI4Bharat/IndicSUPERB"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2208.11761"><img src="../assets/logos/paper.png"></a>
                    <span class="date dataset">February 2023</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">Shrutilipi</h3>
                    <p>Shrutilipi is a dataset with 6,400+ hours of labeled audio across 12 Indian languages, totaling 4.95M sentences, created by mining text audio pairs from All India Radio.</p>
                        <a href="https://github.com/AI4Bharat/Shrutilipi"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2208.12666"><img src="../assets/logos/paper.png"></a>
                    <span class="date model">August 2022</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">Dhwani</h3>
                    <p>Dhwani is a unlabelled audio dataset consisting of 17,000 hours of raw speech data for 40 Indian languages from a wide variety of domains including education, news, technology, and finance </p>
                        <a href="https://github.com/AI4Bharat/IndicWav2Vec/tree/main/data_prep_scripts/urls"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2111.03945"><img src="../assets/logos/paper.png"></a>
                    <span class="date dataset">February 2022</span>
                    <span class="circle"></span>
                </li>
                <li>
                    <h3 class="heading">IndicWav2Vec</h3>
                    <p>IndicWav2Vec is a speech model pretrained on 17,000 hours of unlabelled audio across 40 Indian languages, offering the most extensive language coverage among models tailored for Indian languages. </p>
                        <a href="https://github.com/AI4Bharat/IndicWav2Vec"><img src="../assets/logos/github.png"></a>
                        <a href="https://arxiv.org/abs/2111.03945"><img src="../assets/logos/paper.png"></a>
                    <span class="date model">February 2022</span>
                    <span class="circle"></span>
                </li>
            </ul>
        </div>
    </div>
    <div id="foot_content"></div>
</body>

<script type="text/javascript">
    $('#head_content').load('header.html')
    $('#foot_content').load('footer.html')
</script>

</html>